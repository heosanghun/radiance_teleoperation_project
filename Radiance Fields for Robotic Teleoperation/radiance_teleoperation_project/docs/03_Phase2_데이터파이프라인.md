# Phase 2: ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ (3-4ì£¼)

## ğŸ¯ ëª©í‘œ
ì‹¤ì‹œê°„ ë©€í‹° ì¹´ë©”ë¼ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ë° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“‹ ìƒì„¸ ì‘ì—… ê³„íš

### 2.1 ë©€í‹° ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ (1.5ì£¼)

#### 2.1.1 Camera Node ê°œë°œ
```python
# radiance_camera/src/camera_node.py
#!/usr/bin/env python3

import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import TransformStamped
from cv_bridge import CvBridge
import tf2_ros
import yaml
import threading
import queue
from collections import deque

class MultiCameraNode:
    def __init__(self):
        rospy.init_node('multi_camera_node')
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        self.config = self.load_config()
        
        # ë¸Œë¦¿ì§€ ë° ë²„í¼ ì´ˆê¸°í™”
        self.bridge = CvBridge()
        self.image_buffers = {}
        self.depth_buffers = {}
        self.info_buffers = {}
        
        # ì¹´ë©”ë¼ë³„ ìŠ¤ë ˆë“œ ë° í
        self.camera_threads = {}
        self.image_queues = {}
        
        # TF ë¸Œë¡œë“œìºìŠ¤í„°
        self.tf_broadcaster = tf2_ros.TransformBroadcaster()
        
        # í¼ë¸”ë¦¬ì…” ì´ˆê¸°í™”
        self.init_publishers()
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.init_cameras()
        
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        config_path = rospy.get_param('~config_path', 'config/camera_config.yaml')
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    def init_publishers(self):
        """í¼ë¸”ë¦¬ì…” ì´ˆê¸°í™”"""
        self.publishers = {}
        for camera in self.config['cameras']:
            name = camera['name']
            self.publishers[name] = {
                'image': rospy.Publisher(f'/{name}/image_raw', Image, queue_size=10),
                'depth': rospy.Publisher(f'/{name}/depth_raw', Image, queue_size=10),
                'info': rospy.Publisher(f'/{name}/camera_info', CameraInfo, queue_size=10)
            }
    
    def init_cameras(self):
        """ì¹´ë©”ë¼ ì´ˆê¸°í™” ë° ìŠ¤ë ˆë“œ ì‹œì‘"""
        for camera in self.config['cameras']:
            name = camera['name']
            
            # RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™”
            if 'realsense' in camera.get('type', '').lower():
                self.init_realsense_camera(camera)
            else:
                self.init_standard_camera(camera)
            
            # ë²„í¼ ì´ˆê¸°í™”
            self.image_buffers[name] = deque(maxlen=100)
            self.depth_buffers[name] = deque(maxlen=100)
            self.info_buffers[name] = deque(maxlen=100)
            
            # ìŠ¤ë ˆë“œ ì‹œì‘
            self.start_camera_thread(camera)
    
    def init_realsense_camera(self, camera_config):
        """RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        import pyrealsense2 as rs
        
        pipeline = rs.pipeline()
        config = rs.config()
        
        # ìŠ¤íŠ¸ë¦¼ ì„¤ì •
        config.enable_stream(rs.stream.color, 
                           camera_config['intrinsics']['width'],
                           camera_config['intrinsics']['height'], 
                           rs.format.bgr8, 30)
        config.enable_stream(rs.stream.depth,
                           camera_config['intrinsics']['width'],
                           camera_config['intrinsics']['height'], 
                           rs.format.z16, 30)
        
        # íŒŒì´í”„ë¼ì¸ ì‹œì‘
        profile = pipeline.start(config)
        
        # ì¹´ë©”ë¼ ì •ë³´ ì €ì¥
        camera_config['pipeline'] = pipeline
        camera_config['profile'] = profile
    
    def start_camera_thread(self, camera_config):
        """ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì‹œì‘"""
        name = camera_config['name']
        
        def camera_loop():
            rate = rospy.Rate(30)  # 30 FPS
            
            while not rospy.is_shutdown():
                try:
                    if 'pipeline' in camera_config:
                        # RealSense ì¹´ë©”ë¼
                        frames = camera_config['pipeline'].wait_for_frames()
                        color_frame = frames.get_color_frame()
                        depth_frame = frames.get_depth_frame()
                        
                        if color_frame and depth_frame:
                            # ì´ë¯¸ì§€ ë³€í™˜
                            color_image = np.asanyarray(color_frame.get_data())
                            depth_image = np.asanyarray(depth_frame.get_data())
                            
                            # ë©”ì‹œì§€ ìƒì„± ë° ë°œí–‰
                            self.publish_camera_data(name, color_image, depth_image, camera_config)
                    
                    rate.sleep()
                    
                except Exception as e:
                    rospy.logerr(f"Camera {name} error: {e}")
                    rate.sleep()
        
        # ìŠ¤ë ˆë“œ ì‹œì‘
        thread = threading.Thread(target=camera_loop)
        thread.daemon = True
        thread.start()
        self.camera_threads[name] = thread
    
    def publish_camera_data(self, camera_name, color_image, depth_image, camera_config):
        """ì¹´ë©”ë¼ ë°ì´í„° ë°œí–‰"""
        timestamp = rospy.Time.now()
        
        # ì´ë¯¸ì§€ ë©”ì‹œì§€ ìƒì„±
        color_msg = self.bridge.cv2_to_imgmsg(color_image, "bgr8")
        color_msg.header.stamp = timestamp
        color_msg.header.frame_id = camera_config['camera_frame']
        
        depth_msg = self.bridge.cv2_to_imgmsg(depth_image, "16UC1")
        depth_msg.header.stamp = timestamp
        depth_msg.header.frame_id = camera_config['camera_frame']
        
        # ì¹´ë©”ë¼ ì •ë³´ ë©”ì‹œì§€ ìƒì„±
        info_msg = CameraInfo()
        info_msg.header.stamp = timestamp
        info_msg.header.frame_id = camera_config['camera_frame']
        info_msg.height = camera_config['intrinsics']['height']
        info_msg.width = camera_config['intrinsics']['width']
        info_msg.K = [
            camera_config['intrinsics']['fx'], 0, camera_config['intrinsics']['cx'],
            0, camera_config['intrinsics']['fy'], camera_config['intrinsics']['cy'],
            0, 0, 1
        ]
        info_msg.D = [
            camera_config['distortion']['k1'],
            camera_config['distortion']['k2'],
            camera_config['distortion']['p1'],
            camera_config['distortion']['p2'],
            camera_config['distortion']['k3']
        ]
        
        # ë°œí–‰
        self.publishers[camera_name]['image'].publish(color_msg)
        self.publishers[camera_name]['depth'].publish(depth_msg)
        self.publishers[camera_name]['info'].publish(info_msg)
        
        # ë²„í¼ì— ì €ì¥
        self.image_buffers[camera_name].append(color_image)
        self.depth_buffers[camera_name].append(depth_image)
        self.info_buffers[camera_name].append(info_msg)
        
        # TF ë°œí–‰
        self.publish_camera_tf(camera_name, camera_config, timestamp)
    
    def publish_camera_tf(self, camera_name, camera_config, timestamp):
        """ì¹´ë©”ë¼ TF ë°œí–‰"""
        transform = TransformStamped()
        transform.header.stamp = timestamp
        transform.header.frame_id = camera_config.get('base_frame', 'world')
        transform.child_frame_id = camera_config['camera_frame']
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ ì„¤ì • (ì„¤ì •ì—ì„œ ë¡œë“œ)
        pose = camera_config.get('pose', {'x': 0, 'y': 0, 'z': 0, 'roll': 0, 'pitch': 0, 'yaw': 0})
        
        transform.transform.translation.x = pose['x']
        transform.transform.translation.y = pose['y']
        transform.transform.translation.z = pose['z']
        
        # ì˜¤ì¼ëŸ¬ ê°ë„ë¥¼ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
        from tf.transformations import quaternion_from_euler
        q = quaternion_from_euler(pose['roll'], pose['pitch'], pose['yaw'])
        transform.transform.rotation.x = q[0]
        transform.transform.rotation.y = q[1]
        transform.transform.rotation.z = q[2]
        transform.transform.rotation.w = q[3]
        
        self.tf_broadcaster.sendTransform(transform)

if __name__ == '__main__':
    try:
        node = MultiCameraNode()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass
```

#### 2.1.2 Data Buffer ì‹œìŠ¤í…œ
```python
# radiance_camera/src/data_buffer.py
#!/usr/bin/env python3

import rospy
import numpy as np
from collections import deque
import threading
import time
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge

class DataBuffer:
    def __init__(self, buffer_size=100, sync_threshold=0.1):
        self.buffer_size = buffer_size
        self.sync_threshold = sync_threshold  # ì´ˆ ë‹¨ìœ„
        
        # ì¹´ë©”ë¼ë³„ ë²„í¼
        self.image_buffers = {}
        self.depth_buffers = {}
        self.info_buffers = {}
        self.timestamp_buffers = {}
        
        # ë™ê¸°í™”ëœ ë°ì´í„° ë²„í¼
        self.sync_buffer = deque(maxlen=buffer_size)
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½
        self.lock = threading.Lock()
        
        # ë¸”ëŸ¬ ê°ì§€ ì„¤ì •
        self.blur_threshold = 100  # Laplacian ë¶„ì‚° ì„ê³„ê°’
        
    def add_camera(self, camera_name):
        """ìƒˆë¡œìš´ ì¹´ë©”ë¼ ì¶”ê°€"""
        with self.lock:
            self.image_buffers[camera_name] = deque(maxlen=self.buffer_size)
            self.depth_buffers[camera_name] = deque(maxlen=self.buffer_size)
            self.info_buffers[camera_name] = deque(maxlen=self.buffer_size)
            self.timestamp_buffers[camera_name] = deque(maxlen=self.buffer_size)
    
    def add_data(self, camera_name, image, depth, info, timestamp):
        """ì¹´ë©”ë¼ ë°ì´í„° ì¶”ê°€"""
        with self.lock:
            # ë¸”ëŸ¬ ê²€ì‚¬
            if self.is_image_blurry(image):
                rospy.logwarn(f"Blurry image detected from {camera_name}")
                return False
            
            # ë°ì´í„° ì¶”ê°€
            self.image_buffers[camera_name].append(image)
            self.depth_buffers[camera_name].append(depth)
            self.info_buffers[camera_name].append(info)
            self.timestamp_buffers[camera_name].append(timestamp)
            
            # ë™ê¸°í™” ì‹œë„
            self.try_sync_data()
            return True
    
    def is_image_blurry(self, image):
        """ì´ë¯¸ì§€ ë¸”ëŸ¬ ê²€ì‚¬"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        return laplacian_var < self.blur_threshold
    
    def try_sync_data(self):
        """ëª¨ë“  ì¹´ë©”ë¼ì˜ ë°ì´í„° ë™ê¸°í™” ì‹œë„"""
        if len(self.image_buffers) == 0:
            return
        
        # ëª¨ë“  ì¹´ë©”ë¼ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        for camera_name in self.image_buffers:
            if len(self.timestamp_buffers[camera_name]) == 0:
                return
        
        # ê°€ì¥ ìµœê·¼ íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸°
        latest_timestamps = {}
        for camera_name in self.timestamp_buffers:
            latest_timestamps[camera_name] = self.timestamp_buffers[camera_name][-1]
        
        # ë™ê¸°í™” ê°€ëŠ¥í•œì§€ í™•ì¸
        if self.can_sync_timestamps(latest_timestamps):
            # ë™ê¸°í™”ëœ ë°ì´í„° ìƒì„±
            sync_data = self.create_sync_data(latest_timestamps)
            if sync_data:
                self.sync_buffer.append(sync_data)
    
    def can_sync_timestamps(self, timestamps):
        """íƒ€ì„ìŠ¤íƒ¬í”„ ë™ê¸°í™” ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if len(timestamps) < 2:
            return True
        
        # ëª¨ë“  íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì„ê³„ê°’ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        base_time = min(timestamps.values())
        for timestamp in timestamps.values():
            if abs(timestamp - base_time) > self.sync_threshold:
                return False
        return True
    
    def create_sync_data(self, timestamps):
        """ë™ê¸°í™”ëœ ë°ì´í„° ìƒì„±"""
        sync_data = {
            'timestamp': min(timestamps.values()),
            'cameras': {}
        }
        
        for camera_name in timestamps:
            # í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì— ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° ì°¾ê¸°
            idx = self.find_closest_timestamp(camera_name, timestamps[camera_name])
            if idx >= 0:
                sync_data['cameras'][camera_name] = {
                    'image': self.image_buffers[camera_name][idx],
                    'depth': self.depth_buffers[camera_name][idx],
                    'info': self.info_buffers[camera_name][idx],
                    'timestamp': self.timestamp_buffers[camera_name][idx]
                }
        
        return sync_data if len(sync_data['cameras']) == len(self.image_buffers) else None
    
    def find_closest_timestamp(self, camera_name, target_timestamp):
        """ê°€ì¥ ê°€ê¹Œìš´ íƒ€ì„ìŠ¤íƒ¬í”„ ì¸ë±ìŠ¤ ì°¾ê¸°"""
        timestamps = list(self.timestamp_buffers[camera_name])
        if not timestamps:
            return -1
        
        closest_idx = 0
        min_diff = abs(timestamps[0] - target_timestamp)
        
        for i, timestamp in enumerate(timestamps):
            diff = abs(timestamp - target_timestamp)
            if diff < min_diff:
                min_diff = diff
                closest_idx = i
        
        return closest_idx if min_diff <= self.sync_threshold else -1
    
    def get_latest_sync_data(self):
        """ìµœì‹  ë™ê¸°í™”ëœ ë°ì´í„° ë°˜í™˜"""
        with self.lock:
            if len(self.sync_buffer) > 0:
                return self.sync_buffer[-1]
            return None
    
    def get_all_sync_data(self):
        """ëª¨ë“  ë™ê¸°í™”ëœ ë°ì´í„° ë°˜í™˜"""
        with self.lock:
            return list(self.sync_buffer)
    
    def clear_buffers(self):
        """ëª¨ë“  ë²„í¼ í´ë¦¬ì–´"""
        with self.lock:
            for camera_name in self.image_buffers:
                self.image_buffers[camera_name].clear()
                self.depth_buffers[camera_name].clear()
                self.info_buffers[camera_name].clear()
                self.timestamp_buffers[camera_name].clear()
            self.sync_buffer.clear()
```

### 2.2 ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (1ì£¼)

#### 2.2.1 Image Preprocessing
```python
# radiance_camera/src/image_preprocessor.py
#!/usr/bin/env python3

import cv2
import numpy as np
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge

class ImagePreprocessor:
    def __init__(self, config):
        self.config = config
        self.bridge = CvBridge()
        
        # ì™œê³¡ ë³´ì •ì„ ìœ„í•œ ë§µ ìƒì„±
        self.undistort_maps = {}
        self.init_undistort_maps()
    
    def init_undistort_maps(self):
        """ì™œê³¡ ë³´ì • ë§µ ì´ˆê¸°í™”"""
        for camera_name, camera_config in self.config['cameras'].items():
            # ì¹´ë©”ë¼ ë§¤íŠ¸ë¦­ìŠ¤
            K = np.array([
                [camera_config['intrinsics']['fx'], 0, camera_config['intrinsics']['cx']],
                [0, camera_config['intrinsics']['fy'], camera_config['intrinsics']['cy']],
                [0, 0, 1]
            ])
            
            # ì™œê³¡ ê³„ìˆ˜
            D = np.array([
                camera_config['distortion']['k1'],
                camera_config['distortion']['k2'],
                camera_config['distortion']['p1'],
                camera_config['distortion']['p2'],
                camera_config['distortion']['k3']
            ])
            
            # ì™œê³¡ ë³´ì • ë§µ ìƒì„±
            h, w = camera_config['intrinsics']['height'], camera_config['intrinsics']['width']
            map1, map2 = cv2.initUndistortRectifyMap(K, D, None, K, (w, h), cv2.CV_32FC1)
            
            self.undistort_maps[camera_name] = (map1, map2)
    
    def preprocess_image(self, image, camera_name):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ì™œê³¡ ë³´ì •
        if camera_name in self.undistort_maps:
            map1, map2 = self.undistort_maps[camera_name]
            image = cv2.remap(image, map1, map2, cv2.INTER_LINEAR)
        
        # ìƒ‰ìƒ ì •ê·œí™”
        image = self.normalize_colors(image)
        
        # í•´ìƒë„ ì¡°ì • (í•„ìš”ì‹œ)
        target_size = self.config.get('target_size', None)
        if target_size:
            image = cv2.resize(image, target_size)
        
        return image
    
    def normalize_colors(self, image):
        """ìƒ‰ìƒ ì •ê·œí™”"""
        # BGR to RGB ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        image_normalized = image_rgb.astype(np.float32) / 255.0
        
        return image_normalized
    
    def preprocess_depth(self, depth_image, camera_name):
        """ê¹Šì´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ê¹Šì´ ì´ë¯¸ì§€ë¥¼ ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜
        depth_meters = depth_image.astype(np.float32) / 1000.0
        
        # ë¬´íš¨í•œ ê¹Šì´ê°’ í•„í„°ë§
        depth_meters[depth_meters == 0] = np.nan
        
        return depth_meters
```

#### 2.2.2 Transform ê´€ë¦¬
```python
# radiance_camera/src/transform_manager.py
#!/usr/bin/env python3

import rospy
import numpy as np
import tf2_ros
import tf2_geometry_msgs
from geometry_msgs.msg import TransformStamped, PoseStamped
from sensor_msgs.msg import CameraInfo
import threading

class TransformManager:
    def __init__(self):
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)
        self.tf_broadcaster = tf2_ros.TransformBroadcaster()
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ ìºì‹œ
        self.camera_poses = {}
        self.pose_lock = threading.Lock()
        
        # TF íŠ¸ë¦¬ êµ¬ì„±
        self.setup_tf_tree()
    
    def setup_tf_tree(self):
        """TF íŠ¸ë¦¬ êµ¬ì„±"""
        # ê¸°ë³¸ TF í”„ë ˆì„ ì„¤ì •
        base_frames = ['world', 'map', 'base_link']
        for frame in base_frames:
            self.broadcast_static_transform(frame, 'world', [0, 0, 0], [0, 0, 0, 1])
    
    def broadcast_static_transform(self, child_frame, parent_frame, translation, rotation):
        """ì •ì  TF ë°œí–‰"""
        transform = TransformStamped()
        transform.header.stamp = rospy.Time.now()
        transform.header.frame_id = parent_frame
        transform.child_frame_id = child_frame
        transform.transform.translation.x = translation[0]
        transform.transform.translation.y = translation[1]
        transform.transform.translation.z = translation[2]
        transform.transform.rotation.x = rotation[0]
        transform.transform.rotation.y = rotation[1]
        transform.transform.rotation.z = rotation[2]
        transform.transform.rotation.w = rotation[3]
        
        self.tf_broadcaster.sendTransform(transform)
    
    def get_camera_pose(self, camera_frame, base_frame='world', timeout=1.0):
        """ì¹´ë©”ë¼ í¬ì¦ˆ ì¡°íšŒ"""
        try:
            # TF ë²„í¼ì—ì„œ ë³€í™˜ ì¡°íšŒ
            transform = self.tf_buffer.lookup_transform(
                base_frame, camera_frame, rospy.Time(0), rospy.Duration(timeout)
            )
            
            # ë³€í™˜ì„ í¬ì¦ˆë¡œ ë³€í™˜
            pose = PoseStamped()
            pose.header = transform.header
            pose.pose.position = transform.transform.translation
            pose.pose.orientation = transform.transform.rotation
            
            return pose
            
        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException) as e:
            rospy.logwarn(f"TF lookup failed: {e}")
            return None
    
    def update_camera_pose(self, camera_name, pose):
        """ì¹´ë©”ë¼ í¬ì¦ˆ ì—…ë°ì´íŠ¸"""
        with self.pose_lock:
            self.camera_poses[camera_name] = pose
    
    def get_all_camera_poses(self, base_frame='world'):
        """ëª¨ë“  ì¹´ë©”ë¼ í¬ì¦ˆ ì¡°íšŒ"""
        poses = {}
        with self.pose_lock:
            for camera_name in self.camera_poses:
                pose = self.get_camera_pose(self.camera_poses[camera_name].header.frame_id, base_frame)
                if pose:
                    poses[camera_name] = pose
        return poses
```

### 2.3 Configuration ì‹œìŠ¤í…œ (3ì¼)

#### 2.3.1 ì„¤ì • íŒŒì¼ êµ¬ì¡°
```yaml
# config/camera_config.yaml
# ì¹´ë©”ë¼ ì„¤ì •
cameras:
  - name: "front_camera"
    type: "realsense"
    image_topic: "/front_camera/color/image_raw"
    depth_topic: "/front_camera/depth/image_rect_raw"
    info_topic: "/front_camera/color/camera_info"
    camera_frame: "front_camera_color_optical_frame"
    base_frame: "world"
    
    # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
    intrinsics:
      width: 640
      height: 480
      fx: 615.0
      fy: 615.0
      cx: 320.0
      cy: 240.0
    
    # ì™œê³¡ ê³„ìˆ˜
    distortion:
      k1: 0.0
      k2: 0.0
      k3: 0.0
      p1: 0.0
      p2: 0.0
    
    # ì¹´ë©”ë¼ í¬ì¦ˆ (ê¸°ë³¸ê°’)
    pose:
      x: 0.0
      y: 0.0
      z: 1.0
      roll: 0.0
      pitch: 0.0
      yaw: 0.0
    
    # ìº¡ì²˜ ì„¤ì •
    capture:
      fps: 30
      blur_threshold: 100
      auto_exposure: true
      exposure_time: 10000

  - name: "rear_camera"
    type: "realsense"
    image_topic: "/rear_camera/color/image_raw"
    depth_topic: "/rear_camera/depth/image_rect_raw"
    info_topic: "/rear_camera/color/camera_info"
    camera_frame: "rear_camera_color_optical_frame"
    base_frame: "world"
    
    intrinsics:
      width: 640
      height: 480
      fx: 615.0
      fy: 615.0
      cx: 320.0
      cy: 240.0
    
    distortion:
      k1: 0.0
      k2: 0.0
      k3: 0.0
      p1: 0.0
      p2: 0.0
    
    pose:
      x: 0.0
      y: 0.0
      z: 1.0
      roll: 0.0
      pitch: 0.0
      yaw: 3.14159  # 180ë„
    
    capture:
      fps: 30
      blur_threshold: 100
      auto_exposure: true
      exposure_time: 10000

# ë°ì´í„° ì²˜ë¦¬ ì„¤ì •
processing:
  target_size: [640, 480]
  sync_threshold: 0.1  # ì´ˆ
  buffer_size: 100
  enable_blur_detection: true
  enable_undistortion: true
  enable_normalization: true

# ì €ì¥ ì„¤ì •
storage:
  save_path: "/tmp/radiance_data"
  auto_save: false
  save_format: "rosbag"  # rosbag, images, nerfstudio
  compression: true
```

#### 2.3.2 ì„¤ì • ê´€ë¦¬ì
```python
# radiance_camera/src/config_manager.py
#!/usr/bin/env python3

import rospy
import yaml
import os
from typing import Dict, Any

class ConfigManager:
    def __init__(self, config_path=None):
        if config_path is None:
            config_path = rospy.get_param('~config_path', 'config/camera_config.yaml')
        
        self.config_path = config_path
        self.config = self.load_config()
        
        # ì„¤ì • ë³€ê²½ ê°ì§€ë¥¼ ìœ„í•œ íŒŒì¼ ìˆ˜ì • ì‹œê°„
        self.last_modified = os.path.getmtime(config_path)
    
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            config = self.set_defaults(config)
            
            rospy.loginfo(f"Configuration loaded from {self.config_path}")
            return config
            
        except Exception as e:
            rospy.logerr(f"Failed to load config: {e}")
            return self.get_default_config()
    
    def set_defaults(self, config):
        """ê¸°ë³¸ê°’ ì„¤ì •"""
        # ì¹´ë©”ë¼ ê¸°ë³¸ê°’
        for camera in config.get('cameras', []):
            if 'capture' not in camera:
                camera['capture'] = {}
            
            camera['capture'].setdefault('fps', 30)
            camera['capture'].setdefault('blur_threshold', 100)
            camera['capture'].setdefault('auto_exposure', True)
            camera['capture'].setdefault('exposure_time', 10000)
        
        # ì²˜ë¦¬ ê¸°ë³¸ê°’
        if 'processing' not in config:
            config['processing'] = {}
        
        config['processing'].setdefault('target_size', [640, 480])
        config['processing'].setdefault('sync_threshold', 0.1)
        config['processing'].setdefault('buffer_size', 100)
        config['processing'].setdefault('enable_blur_detection', True)
        config['processing'].setdefault('enable_undistortion', True)
        config['processing'].setdefault('enable_normalization', True)
        
        # ì €ì¥ ê¸°ë³¸ê°’
        if 'storage' not in config:
            config['storage'] = {}
        
        config['storage'].setdefault('save_path', '/tmp/radiance_data')
        config['storage'].setdefault('auto_save', False)
        config['storage'].setdefault('save_format', 'rosbag')
        config['storage'].setdefault('compression', True)
        
        return config
    
    def get_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            'cameras': [],
            'processing': {
                'target_size': [640, 480],
                'sync_threshold': 0.1,
                'buffer_size': 100,
                'enable_blur_detection': True,
                'enable_undistortion': True,
                'enable_normalization': True
            },
            'storage': {
                'save_path': '/tmp/radiance_data',
                'auto_save': False,
                'save_format': 'rosbag',
                'compression': True
            }
        }
    
    def check_for_updates(self):
        """ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸"""
        try:
            current_modified = os.path.getmtime(self.config_path)
            if current_modified > self.last_modified:
                self.config = self.load_config()
                self.last_modified = current_modified
                return True
        except Exception as e:
            rospy.logwarn(f"Failed to check config updates: {e}")
        
        return False
    
    def get_camera_config(self, camera_name):
        """íŠ¹ì • ì¹´ë©”ë¼ ì„¤ì • ë°˜í™˜"""
        for camera in self.config.get('cameras', []):
            if camera['name'] == camera_name:
                return camera
        return None
    
    def get_processing_config(self):
        """ì²˜ë¦¬ ì„¤ì • ë°˜í™˜"""
        return self.config.get('processing', {})
    
    def get_storage_config(self):
        """ì €ì¥ ì„¤ì • ë°˜í™˜"""
        return self.config.get('storage', {})
    
    def update_config(self, updates):
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        def deep_update(d, u):
            for k, v in u.items():
                if isinstance(v, dict):
                    d[k] = deep_update(d.get(k, {}), v)
                else:
                    d[k] = v
            return d
        
        self.config = deep_update(self.config, updates)
        
        # íŒŒì¼ì— ì €ì¥
        try:
            with open(self.config_path, 'w') as f:
                yaml.dump(self.config, f, default_flow_style=False)
            rospy.loginfo("Configuration updated and saved")
        except Exception as e:
            rospy.logerr(f"Failed to save config: {e}")
```

## âœ… ê²€ì¦ ê¸°ì¤€

### ë°ì´í„° ìˆ˜ì§‘ ê²€ì¦
- [ ] ë©€í‹° ì¹´ë©”ë¼ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° (30 FPS)
- [ ] ì´ë¯¸ì§€-ê¹Šì´ ë™ê¸°í™” (ì§€ì—° < 100ms)
- [ ] ë¸”ëŸ¬ ê°ì§€ ë° í•„í„°ë§ ì •ìƒ ì‘ë™
- [ ] TF íŠ¸ë¦¬ ì •ìƒ êµ¬ì„± ë° ë°œí–‰

### ë°ì´í„° ì²˜ë¦¬ ê²€ì¦
- [ ] ì™œê³¡ ë³´ì • ì •ìƒ ì‘ë™
- [ ] ìƒ‰ìƒ ì •ê·œí™” (0-1 ë²”ìœ„)
- [ ] í•´ìƒë„ ì¡°ì • ì •ìƒ ì‘ë™
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

### ì„¤ì • ì‹œìŠ¤í…œ ê²€ì¦
- [ ] YAML ì„¤ì • íŒŒì¼ ì •ìƒ ë¡œë“œ
- [ ] ì‹¤ì‹œê°„ ì„¤ì • ì—…ë°ì´íŠ¸
- [ ] ê¸°ë³¸ê°’ ìë™ ì„¤ì •
- [ ] ì„¤ì • ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬

## ğŸš¨ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤
1. **ì¹´ë©”ë¼ ë™ê¸°í™” ì‹¤íŒ¨**
   - í•´ê²°: íƒ€ì„ìŠ¤íƒ¬í”„ ì„ê³„ê°’ ì¡°ì •, ë„¤íŠ¸ì›Œí¬ ì§€ì—° í™•ì¸
2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤**
   - í•´ê²°: ë²„í¼ í¬ê¸° ì¡°ì •, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”
3. **TF ë³€í™˜ ì‹¤íŒ¨**
   - í•´ê²°: TF íŠ¸ë¦¬ êµ¬ì„± í™•ì¸, íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¡°ì •

### ì„±ëŠ¥ ìµœì í™” íŒ
- ë©€í‹°ìŠ¤ë ˆë”© í™œìš©ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬
- ë©”ëª¨ë¦¬ ë§¤í•‘ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
- GPU ê°€ì† í™œìš© (ê°€ëŠ¥ì‹œ)
